---
title: "GPT-2 Tracery Twitterbot"
excerpt: "Development of a Twitterbot using [Tracery](https://cheapbotsdonequick.com/) to post GPT-2 generated content<br><br><img src='/images/gpt.png'>"
collection: portfolio
---

## Problem
Can we train a GPT-2 model to learn gamer slang (gamer girls) and create a twitter bot with it. Can GPT-2 models be able to parse out the nuances of cultural differences, and not just racial bias

### Goals
* Sentiment Analysis - Download and analyze sentiment expression in tweets by popular gamers and within popular gaming hashtags 
  * Analyze for valence
* Twitterbot - Create a Twitterbot to tweet our tweets generated by a GPT-2 model that learned on positive tweets

### Sentiment Analysis
- Downloaded tweets from prominent gamer twitter accounts (Ninja, Pokimane, LilyPichu)
- Analyzed tweets for sentiment
- Trained a recurrent neural network (RNN) classifier with 800,000 labeled tweets
- Used this model to separate positive and negative tweets


## Generating Tweets
### Using a GPT-2 Model we:
- Learned on tweets from Game Twitter Personalities
- Used existing GPT-2 Google Colab model
- Input a single-column csv
- Used a 124M “small” model
- Carried out 2000 steps, temperature of .7
- Generated a .txt file of 1000 tweets at a time

### Creating a Twitterbot
- Using Tracery, we were able to create a bot to tweet out our generated tweets
- Created “bot” Twitter Account
- Set to tweet every 6 hours
- Created set of rules to generate game-related Tweets
- Two types: human created (by us) and GPT-2 generated

